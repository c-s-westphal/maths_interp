# Operand Feature Interaction in Arithmetic Reasoning

An interpretability experiment studying how small language models internally represent numbers and combine them during arithmetic operations.

## Overview

This project investigates how the Pythia-160M language model:
- Represents operands (numbers) across different layers
- Combines operand features to produce arithmetic answers
- Shows different interaction patterns for different operations (add, sub, mul, max, min)
- Differs in representation between correct vs incorrect predictions

## Hypothesis

**Multiplication should show higher feature interaction than max/min operations** because:
- Multiplication requires computing relationships between digit positions
- Max/min can be solved by comparing numbers independently
- Addition shows moderate interaction (carry operations)

## Project Structure

```
maths_interp/
‚îú‚îÄ‚îÄ README.md                 # This file
‚îú‚îÄ‚îÄ requirements.txt          # Python dependencies
‚îú‚îÄ‚îÄ src/                      # Source code
‚îÇ   ‚îú‚îÄ‚îÄ config.py            # Configuration and constants
‚îÇ   ‚îú‚îÄ‚îÄ dataset_generator.py # Generate arithmetic dataset
‚îÇ   ‚îú‚îÄ‚îÄ tokenizer_utils.py   # Tokenization and position finding
‚îÇ   ‚îú‚îÄ‚îÄ model_inference.py   # Model inference and hidden states
‚îÇ   ‚îú‚îÄ‚îÄ probe_training.py    # Train numeric-decoding probes
‚îÇ   ‚îú‚îÄ‚îÄ interaction_analysis.py  # Compute interaction scores
‚îÇ   ‚îú‚îÄ‚îÄ visualization.py     # Generate plots
‚îÇ   ‚îî‚îÄ‚îÄ main.py             # Main pipeline orchestrator
‚îú‚îÄ‚îÄ data/                     # Generated datasets
‚îú‚îÄ‚îÄ results/                  # Saved models and features
‚îÇ   ‚îî‚îÄ‚îÄ probes/              # Per-layer probe models
‚îî‚îÄ‚îÄ plots/                    # Generated visualizations
```

## Installation

```bash
# Create virtual environment (recommended)
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

## Usage

### Quick Start: Run Full Pipeline

```bash
cd src
python main.py
```

This will:
1. Generate ~3,000 arithmetic examples (5 operations √ó 3 difficulties √ó 200 examples)
2. Tokenize and locate operand positions
3. Run Pythia-160M inference and extract hidden states
4. Train numeric-decoding probes for each layer
5. Compute interaction scores for all operations and layers
6. Generate visualization plots

**Expected runtime:** 20-40 minutes on CPU, 5-10 minutes on GPU

### Skip Already-Computed Steps

```bash
python main.py --skip-existing
```

### Run Individual Steps

```python
# Generate dataset only
python dataset_generator.py

# Test tokenization
python tokenizer_utils.py

# Run model inference
python model_inference.py

# Train probes
python probe_training.py

# Compute interactions
python interaction_analysis.py

# Generate plots
python visualization.py
```

## Methodology

### 1. Dataset Generation

**Operations:** add, sub, mul, max, min

**Difficulty levels:**
- Easy: 1-2 digit numbers (1-99)
- Medium: 3 digit numbers (100-999)
- Hard: 4 digit numbers (1000-9999)

**Prompt formats:**
```
add: "12 + 7 ="
sub: "34 - 19 ="
mul: "5 * 17 ="
max: "max(5, 17) ="
min: "min(12, 3) ="
```

### 2. Operand Position Finding

For each prompt, we:
1. Tokenize the full prompt
2. Separately tokenize operand strings (x1 and x2)
3. Find token subsequences in the prompt
4. Record the position of the **last token** of each operand

### 3. Hidden State Extraction

Run model with `output_hidden_states=True` and extract:
- `h1_‚Ñì`: Hidden state at operand 1 position, layer ‚Ñì
- `h2_‚Ñì`: Hidden state at operand 2 position, layer ‚Ñì
- `Z`: Logit of the predicted answer token

### 4. Numeric-Decoding Probes

For each layer ‚Ñì, train two probes:
- **Probe 1:** `h1_‚Ñì ‚Üí xÃÇ1` (predict operand 1 value)
- **Probe 2:** `h2_‚Ñì ‚Üí xÃÇ2` (predict operand 2 value)

**Architecture:** MLP with one hidden layer (d ‚Üí 64 ‚Üí 1)

**Features:** Extract penultimate layer activations as `F1_‚Ñì` and `F2_‚Ñì`

### 5. Interaction Score Computation

For each layer ‚Ñì and operation type:

1. Train predictor: `g([F1, F2]) ‚Üí Z`
2. Compute performance scores:
   - `S_all`: Performance with true F1 and F2
   - `S_shuf_F1`: Performance with shuffled F1
   - `S_shuf_F2`: Performance with shuffled F2
   - `S_shuf_both`: Performance with both shuffled

3. Compute interaction:
```
Œî1 = S_all - S_shuf_F1
Œî2 = S_all - S_shuf_F2
Œî12 = S_all - S_shuf_both

Interaction = max(0, Œî12 - 0.5 √ó (Œî1 + Œî2))
```

**Interpretation:** Higher interaction = features must be combined to predict output

## Expected Results

### Probe Quality
- **Early layers:** Lower R¬≤ scores (operands not yet well-represented)
- **Middle/late layers:** Higher R¬≤ scores (clear numeric representations)
- **Final layers:** May decrease if model focuses on answer generation

### Interaction Patterns

**Multiplication vs Max/Min:**
- Multiplication should show **higher interaction scores** in middle/late layers
- Max/min should show **lower interaction** (more independent processing)
- Addition should be **intermediate**

**Correct vs Incorrect:**
- Correct predictions may show:
  - Higher interaction (better feature integration)
  - More consistent patterns across layers
- Incorrect predictions may show:
  - Lower interaction (failed to combine features)
  - Irregular patterns

## Generated Plots

1. **`interaction_by_layer.png`**
   - Interaction score vs layer for all operations
   - Compare mul (high) vs max/min (low)

2. **`interaction_correct_vs_incorrect_mul.png`**
   - Multiplication: correct vs incorrect examples
   - Check if correct shows higher interaction

3. **`probe_quality.png`**
   - R¬≤ and MAE for numeric probes across layers
   - Verify probes successfully decode numbers

4. **`accuracy_by_operation.png`**
   - Model accuracy for each operation type
   - Context for interaction results

5. **`interaction_heatmap.png`**
   - Heatmap: operations √ó layers
   - Visual summary of all patterns

## Configuration

Edit `src/config.py` to modify:
- Model name (`MODEL_NAME`)
- Dataset size (`EXAMPLES_PER_OP_DIFFICULTY`)
- Probe architecture (`PROBE_HIDDEN_DIM`)
- Training hyperparameters
- File paths

## Output Files

**Data:**
- `data/arithmetic_dataset.pkl`: Generated dataset with predictions

**Results:**
- `results/hidden_states.npz`: Extracted hidden states (h1, h2, Z)
- `results/features.npz`: Probe features (F1, F2) and metrics
- `results/probes/`: Per-layer probe model weights
- `results/interaction_scores.csv`: All interaction scores
- `results/interaction_scores_correct.csv`: Correct examples only
- `results/interaction_scores_incorrect.csv`: Incorrect examples only

**Plots:**
- `plots/*.png`: All generated visualizations

## Success Criteria

‚úÖ **Experiment is successful if:**

1. Probes decode operands with R¬≤ > 0.5 in middle/late layers
2. Multiplication shows noticeably higher interaction than max/min
3. Visible differences between operations across layers
4. Some differences between correct vs incorrect predictions

‚ùå **Troubleshooting:**

- **Low probe R¬≤:** Model may not represent numbers well (try different difficulty levels)
- **No interaction differences:** Try larger dataset or different operations
- **Model accuracy too low:** Use easier examples or smaller number ranges

## Future Extensions

1. **PID (Partial Information Decomposition):** More rigorous synergy quantification
2. **SAEs (Sparse Autoencoders):** Discover interpretable features automatically
3. **Causal interventions:** Directly manipulate operand features
4. **Attention analysis:** How do attention patterns differ by operation?
5. **Scaling laws:** How do patterns change with model size?

## References

- **Pythia Models:** Biderman et al. (2023) - "Pythia: A Suite for Analyzing Large Language Models"
- **Mechanistic Interpretability:** Elhage et al. (2021) - "A Mathematical Framework for Transformer Circuits"
- **Numeric Reasoning:** Razeghi et al. (2022) - "Impact of Pretraining Term Frequencies on Few-Shot Reasoning"

## License

MIT License - Feel free to use for research and education.

## Citation

If you use this code for research, please cite:

```bibtex
@misc{arithmetic_interaction_2024,
  title={Operand Feature Interaction in Arithmetic Reasoning},
  author={Your Name},
  year={2024},
  url={https://github.com/yourusername/maths_interp}
}
```

## Contact

For questions or issues, please open an issue on GitHub or contact [your email].

---

**Happy experimenting! üî¨**
